{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.00515 \n",
      " [[-0.09576704  0.61926496 -0.64923644]\n",
      " [ 1.5735693   0.92762113 -0.84375721]\n",
      " [ 0.73249066  0.84330904 -0.81611741]\n",
      " [-0.47443712 -0.35836929 -0.97443074]] \n",
      " [ 0.55744743  1.51085937  2.12309408]\n",
      "200 0.518915 \n",
      " [[-1.20510519  0.12391334  0.95545399]\n",
      " [ 0.63723081  0.41628206  0.60392094]\n",
      " [ 0.95099103  0.29353434 -0.48484296]\n",
      " [-0.76693422 -0.14341538 -0.89688635]] \n",
      " [-0.21757105  0.81603706  3.59293461]\n",
      "400 0.427704 \n",
      " [[-1.73363912  0.23079357  1.37710714]\n",
      " [ 0.5005883   0.42755333  0.72929198]\n",
      " [ 1.46668541  0.12487977 -0.83188319]\n",
      " [-0.9103421   0.06696576 -0.96385932]] \n",
      " [-0.66392386  0.65892124  4.1964035 ]\n",
      "600 0.354023 \n",
      " [[-2.14886212  0.33604822  1.6870755 ]\n",
      " [ 0.40230229  0.44780451  0.80732697]\n",
      " [ 1.93161678 -0.02114696 -1.15078735]\n",
      " [-1.07973588  0.21392256 -0.94142115]] \n",
      " [-1.04441404  0.56493348  4.67088079]\n",
      "800 0.281645 \n",
      " [[-2.48695421  0.41979462  1.94142175]\n",
      " [ 0.32836595  0.46133542  0.86773235]\n",
      " [ 2.34419036 -0.14655599 -1.43795049]\n",
      " [-1.23478639  0.32381767 -0.89626485]] \n",
      " [-1.36323774  0.48275852  5.07187986]\n",
      "1000 0.232114 \n",
      " [[-2.7549305   0.47561386  2.15357757]\n",
      " [ 0.2822668   0.45287454  0.92229289]\n",
      " [ 2.69785976 -0.24688855 -1.69128525]\n",
      " [-1.36333537  0.40603542 -0.84993243]] \n",
      " [-1.61833882  0.39121786  5.41852331]\n",
      "1200 0.210604 \n",
      " [[-2.99305487  0.53366208  2.33365417]\n",
      " [ 0.22898124  0.45280078  0.9756524 ]\n",
      " [ 2.99967313 -0.32018065 -1.9198066 ]\n",
      " [-1.50217521  0.50238782 -0.80744469]] \n",
      " [-1.84677446  0.31252488  5.72565126]\n",
      "1400 0.192649 \n",
      " [[-3.20919847  0.58885044  2.49461126]\n",
      " [ 0.18014595  0.45345747  1.02383077]\n",
      " [ 3.27890706 -0.39157605 -2.12764359]\n",
      " [-1.63372576  0.59234762 -0.76585376]] \n",
      " [-2.05530763  0.24367206  6.00303841]\n",
      "1600 0.17743 \n",
      " [[-3.40677619  0.64044678  2.64059329]\n",
      " [ 0.13525783  0.45451254  1.06766427]\n",
      " [ 3.53853726 -0.46013495 -2.3187139 ]\n",
      " [-1.75806236  0.676485   -0.72565478]] \n",
      " [-2.24671745  0.18189101  6.25623035]\n",
      "1800 0.16437 \n",
      " [[-3.58852291  0.68850422  2.77428222]\n",
      " [ 0.09366626  0.45575604  1.1080128 ]\n",
      " [ 3.78095484 -0.52554792 -2.49571657]\n",
      " [-1.87561023  0.75543416 -0.68705612]] \n",
      " [-2.42333817  0.12552504  6.48922014]\n",
      "2000 0.153044 \n",
      " [[-3.7566421   0.73326349  2.89763927]\n",
      " [ 0.05488211  0.45707634  1.14547694]\n",
      " [ 4.00817299 -0.5878219  -2.66065931]\n",
      " [-1.98687828  0.82975787 -0.65011132]] \n",
      " [-2.58710861  0.07350085  6.70501518]\n"
     ]
    }
   ],
   "source": [
    "# Lab 6 Softmax Classifier\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "x_data = [[1, 2, 1, 1],\n",
    "          [2, 1, 3, 2],\n",
    "          [3, 1, 3, 4],\n",
    "          [4, 1, 5, 5],\n",
    "          [1, 7, 5, 5],\n",
    "          [1, 2, 5, 6],\n",
    "          [1, 6, 6, 6],\n",
    "          [1, 7, 7, 7]]\n",
    "y_data = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [1, 0, 0],\n",
    "          [1, 0, 0]]\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 4])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "nb_classes = 3\n",
    "\n",
    "W = tf.Variable(tf.random_normal([4, nb_classes]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name='bias')\n",
    "\n",
    "# tf.nn.softmax computes softmax activations\n",
    "# softmax = exp(logits) / reduce_sum(exp(logits), dim)\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "# Cross entropy cost/loss\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))   #去掉第二维（列），把所有列加到1列，变为8行1列\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(2001):\n",
    "        sess.run(optimizer, feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step, sess.run(cost,feed_dict={X: x_data, Y: y_data}),\"\\n\",sess.run(W),\"\\n\",sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.53206366e-01   6.45797729e-01   9.95982904e-04]\n",
      " [  9.09435377e-02   9.09011185e-01   4.53116045e-05]\n",
      " [  3.73523980e-02   9.62643683e-01   3.93639539e-06]\n",
      " [  1.33602265e-02   9.86639798e-01   2.21808101e-08]\n",
      " [  8.47969353e-01   1.52030647e-01   3.72100441e-12]\n",
      " [  1.64235279e-01   8.35764647e-01   7.75817171e-08]\n",
      " [  6.99712157e-01   3.00287932e-01   4.43950519e-12]\n",
      " [  7.79883862e-01   2.20116094e-01   5.68743932e-14]]\n",
      "\n",
      " [[ -1.04070282e+00  -4.37268943e-01  -6.91178036e+00]\n",
      " [ -2.39751649e+00  -9.53978822e-02  -1.00019474e+01]\n",
      " [ -3.28735828e+00  -3.80719416e-02  -1.24452448e+01]\n",
      " [ -4.31547308e+00  -1.34502528e-02  -1.76240387e+01]\n",
      " [ -1.64910778e-01  -1.88367319e+00  -2.63170280e+01]\n",
      " [ -1.80645525e+00  -1.79408222e-01  -1.63719349e+01]\n",
      " [ -3.57086241e-01  -1.20301354e+00  -2.61404781e+01]\n",
      " [ -2.48610273e-01  -1.51360011e+00  -3.04979305e+01]]\n",
      "\n",
      " [[ -0.          -0.          -6.91178036]\n",
      " [ -0.          -0.         -10.0019474 ]\n",
      " [ -0.          -0.         -12.44524479]\n",
      " [ -0.          -0.01345025  -0.        ]\n",
      " [ -0.          -1.88367319  -0.        ]\n",
      " [ -0.          -0.17940822  -0.        ]\n",
      " [ -0.35708624  -0.          -0.        ]\n",
      " [ -0.24861027  -0.          -0.        ]]\n",
      "\n",
      " [  6.91178036  10.0019474   12.44524479   0.01345025   1.88367319\n",
      "   0.17940822   0.35708624   0.24861027]\n",
      "\n",
      " 4.00515\n"
     ]
    }
   ],
   "source": [
    "x_data = [[1, 2, 1, 1],\n",
    "          [2, 1, 3, 2],\n",
    "          [3, 1, 3, 4],\n",
    "          [4, 1, 5, 5],\n",
    "          [1, 7, 5, 5],\n",
    "          [1, 2, 5, 6],\n",
    "          [1, 6, 6, 6],\n",
    "          [1, 7, 7, 7]]\n",
    "y_data = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [1, 0, 0],\n",
    "          [1, 0, 0]]\n",
    "W=[[-0.09576704  ,0.61926496 ,-0.64923644],\n",
    " [1.5735693  , 0.92762113, -0.84375721],\n",
    " [ 0.73249066 , 0.84330904, -0.81611741],\n",
    " [-0.47443712, -0.35836929 ,-0.97443074]]\n",
    "b= [ 0.55744743 , 1.51085937 , 2.12309408]\n",
    "X = tf.placeholder(\"float\", [None, 4])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "sess=tf.Session()\n",
    "print(sess.run(hypothesis,feed_dict={X: x_data, Y: y_data}))\n",
    "print(\"\\n\",sess.run(tf.log(hypothesis),feed_dict={X: x_data, Y: y_data}))\n",
    "print(\"\\n\",sess.run(Y*tf.log(hypothesis),feed_dict={X: x_data, Y: y_data}))\n",
    "print(\"\\n\",sess.run(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1),feed_dict={X: x_data, Y: y_data}))\n",
    "print(\"\\n\",sess.run(tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1)),feed_dict={X: x_data, Y: y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_42:0\", dtype=float32)\n",
      "0 Cost:  22662.1 \n",
      "Prediction:\n",
      " [ 14.63983059  26.5960598   21.79611778  21.39977074  24.36887169] [ 1.70463467] [-0.16827568] [-0.4957386] [-0.37660936]\n",
      "200 Cost:  8.65489 \n",
      "Prediction:\n",
      " [ 148.40167236  186.95878601  180.01626587  193.68281555  146.59565735] [ 2.003546] [ 0.18925953] [-0.16831425] [-0.37333924]\n",
      "400 Cost:  7.86716 \n",
      "Prediction:\n",
      " [ 148.60627747  186.81759644  180.07780457  193.73632812  146.40278625] [ 1.97704542] [ 0.21865304] [-0.17113899] [-0.3738575]\n",
      "600 Cost:  7.15948 \n",
      "Prediction:\n",
      " [ 148.7999115   186.68395996  180.13598633  193.78739929  146.21983337] [ 1.95183623] [ 0.24644259] [-0.17365664] [-0.37436461]\n",
      "800 Cost:  6.52373 \n",
      "Prediction:\n",
      " [ 148.98312378  186.55744934  180.19096375  193.83609009  146.04629517] [ 1.92785156] [ 0.27271301] [-0.17588431] [-0.37486112]\n",
      "1000 Cost:  5.95253 \n",
      "Prediction:\n",
      " [ 149.15646362  186.43768311  180.24290466  193.88253784  145.88166809] [ 1.90502608] [ 0.29754496] [-0.17783774] [-0.37534705]\n",
      "1200 Cost:  5.43922 \n",
      "Prediction:\n",
      " [ 149.32048035  186.32437134  180.29203796  193.9269104   145.72549438] [ 1.88329983] [ 0.3210144] [-0.17953232] [-0.37582305]\n",
      "1400 Cost:  4.97788 \n",
      "Prediction:\n",
      " [ 149.47566223  186.21710205  180.33842468  193.96929932  145.57736206] [ 1.86261523] [ 0.34319353] [-0.18098256] [-0.37629023]\n",
      "1600 Cost:  4.56314 \n",
      "Prediction:\n",
      " [ 149.62246704  186.11560059  180.38227844  194.00975037  145.43675232] [ 1.84291804] [ 0.3641507] [-0.18220206] [-0.37674764]\n",
      "1800 Cost:  4.19029 \n",
      "Prediction:\n",
      " [ 149.76130676  186.01953125  180.4236908   194.04841614  145.30334473] [ 1.82415652] [ 0.3839505] [-0.18320365] [-0.37719706]\n",
      "2000 Cost:  3.85497 \n",
      "Prediction:\n",
      " [ 149.89265442  185.92860413  180.46281433  194.08538818  145.17674255] [ 1.80628181] [ 0.40265432] [-0.18399982] [-0.37763792]\n"
     ]
    }
   ],
   "source": [
    "x1_data = [73., 93., 89., 96., 73.]\n",
    "x2_data = [80., 88., 91., 98., 66.]\n",
    "x3_data = [75., 93., 90., 100., 70.]\n",
    "\n",
    "y_data = [152., 185., 180., 196., 142.]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "x1 = tf.placeholder(tf.float32)\n",
    "x2 = tf.placeholder(tf.float32)\n",
    "x3 = tf.placeholder(tf.float32)\n",
    "\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([1]), name='weight1')\n",
    "w2 = tf.Variable(tf.random_normal([1]), name='weight2')\n",
    "w3 = tf.Variable(tf.random_normal([1]), name='weight3')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = x1 * w1 + x2 * w2 + x3 * w3 + b\n",
    "print(hypothesis)\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize. Need a very small learning rate for this data set\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                                   feed_dict={x1: x1_data, x2: x2_data, x3: x3_data, Y: y_data})\n",
    "    if step % 200 == 0:\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val,sess.run(w1),sess.run(w2),sess.run(w3),sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4.43826914   0.86148399   0.21436663   3.66509581  10.08771896]\n",
      "3.85339\n"
     ]
    }
   ],
   "source": [
    "x1_data = [73., 93., 89., 96., 73.]\n",
    "x2_data = [80., 88., 91., 98., 66.]\n",
    "x3_data = [75., 93., 90., 100., 70.]\n",
    "\n",
    "y_data = [152., 185., 180., 196., 142.]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "x1 = tf.placeholder(tf.float32)\n",
    "x2 = tf.placeholder(tf.float32)\n",
    "x3 = tf.placeholder(tf.float32)\n",
    "\n",
    "Y = tf.placeholder(tf.float32)\n",
    "w1=[ 1.80628181]\n",
    "w2=[ 0.40265432]\n",
    "w3=[-0.18399982]\n",
    "b=[-0.37763792]\n",
    "hypothesis = x1 * w1 + x2 * w2 + x3 * w3 + b\n",
    "\n",
    "sess = tf.Session()\n",
    "print(sess.run(tf.square(hypothesis - Y),feed_dict={x1: x1_data, x2: x2_data, x3: x3_data, Y: y_data}))\n",
    "print(sess.run(tf.reduce_mean(tf.square(hypothesis - Y)),feed_dict={x1: x1_data, x2: x2_data, x3: x3_data, Y: y_data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 457.62237549  457.62237549  149.89328003  607.515625    457.62237549]\n",
      " [ 547.62237549  547.62237549  185.92816162  733.55053711  547.62237549]\n",
      " [ 540.62237549  540.62237549  180.46299744  721.08538818  540.62237549]\n",
      " [ 591.62237549  591.62237549  194.08555603  785.70794678  591.62237549]\n",
      " [ 414.62237549  414.62237549  145.17611694  559.79846191  414.62237549]]\n"
     ]
    }
   ],
   "source": [
    "x=[ [73., 93., 89., 96., 73.], [80., 88., 91., 98., 66.],[75., 93., 90., 100., 70.]]\n",
    "x=tf.transpose(x,perm=[1,0])\n",
    "W=[[ 1.80628181,1],\n",
    "   [ 0.40265432,2],\n",
    "   [-0.18399982,3]]\n",
    "b=[-0.37763792]\n",
    "y=tf.matmul(x,W)+b\n",
    "p=[[0.,0.,1.,1.,0.],[1.,1.,0.,1.,1.]]\n",
    "sess = tf.Session()\n",
    "print(sess.run(tf.matmul(y,p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 228.  274.  270.  294.  209.]\n"
     ]
    }
   ],
   "source": [
    "x=[ [73., 93., 89., 96., 73.], [80., 88., 91., 98., 66.],[75., 93., 90., 100., 70.]]\n",
    "y=tf.reduce_sum(x,axis=0)\n",
    "sess = tf.Session()\n",
    "print(sess.run(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
