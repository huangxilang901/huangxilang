{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a=tf.constant(2,name='a')\n",
    "b=tf.constant(4,name='b')\n",
    "c=tf.Variable(a*b,name='c')\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "session=tf.Session()\n",
    "session.run(init)\n",
    "session.run(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "y_hat=tf.constant(36,name='y_hat')\n",
    "y=tf.constant(39,name='y')\n",
    "loss=tf.Variable((y_hat-y)**2,name='loss') #平方 **2\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(sess.run(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid([0,12]) =  [ 0.5        0.9999938]\n"
     ]
    }
   ],
   "source": [
    "z=[0,12]\n",
    "x = tf.placeholder(tf.float32)\n",
    "sess=tf.Session()\n",
    "print (\"sigmoid([0,12]) = \" , sess.run(tf.sigmoid(x),feed_dict={x:z}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "epoch=1\n",
    "for i in range(10):\n",
    "    epoch+=1\n",
    "    \n",
    "    print(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 w:-0.1592707633972168,b:0.1592707633972168 loss: 58.446\n",
      "0 w:-0.2999119162559509,b:0.30281174182891846 loss: 47.5508\n",
      "0 w:-0.4443925619125366,b:0.45337575674057007 loss: 52.403\n",
      "0 w:-0.5782610177993774,b:0.595880925655365 loss: 47.0184\n",
      "0 w:-0.697006344795227,b:0.7250654101371765 loss: 38.6995\n",
      "0 w:-0.8124417662620544,b:0.853471040725708 loss: 38.2926\n",
      "0 w:-0.9332694411277771,b:0.9909645915031433 loss: 43.9702\n",
      "0 w:-1.0497984886169434,b:1.126686692237854 loss: 42.9069\n",
      "0 w:-1.154980182647705,b:1.2521443367004395 loss: 36.7144\n",
      "0 w:-1.2580723762512207,b:1.3781459331512451 loss: 37.0848\n",
      "0 w:-1.355359673500061,b:1.5000628232955933 loss: 34.7663\n",
      "0 w:-1.4486773014068604,b:1.6200425624847412 loss: 33.7146\n",
      "0 w:-1.5424909591674805,b:1.743876576423645 loss: 35.9615\n",
      "0 w:-1.6183913946151733,b:1.8468101024627686 loss: 24.8779\n",
      "0 w:-1.7013167142868042,b:1.9624383449554443 loss: 31.4308\n",
      "0 w:-1.7756386995315552,b:2.0690741539001465 loss: 26.7636\n",
      "0 w:-1.8473989963531494,b:2.175107955932617 loss: 26.4925\n",
      "0 w:-1.9156697988510132,b:2.2790894508361816 loss: 25.5053\n",
      "0 w:-1.9806466102600098,b:2.3811957836151123 loss: 24.6201\n",
      "0 w:-2.039322853088379,b:2.4764244556427 loss: 21.4374\n",
      "0 w:-2.1010262966156006,b:2.579960584640503 loss: 25.3663\n",
      "0 w:-2.1656291484832764,b:2.6921656131744385 loss: 29.8209\n",
      "0 w:-2.220907688140869,b:2.7916669845581055 loss: 23.4727\n",
      "0 w:-2.273888349533081,b:2.8906309604644775 loss: 23.2408\n",
      "0 w:-2.322115421295166,b:2.984248161315918 loss: 20.8155\n",
      "0 w:-2.370004415512085,b:3.081003189086914 loss: 22.2529\n",
      "0 w:-2.41746187210083,b:3.180966854095459 loss: 23.7723\n",
      "0 w:-2.4600884914398193,b:3.274745225906372 loss: 20.9376\n",
      "0 w:-2.500380754470825,b:3.367511034011841 loss: 20.503\n",
      "0 w:-2.5409812927246094,b:3.4655463695526123 loss: 22.9146\n",
      "0 w:-2.575984001159668,b:3.554399251937866 loss: 18.8356\n",
      "0 w:-2.6120026111602783,b:3.650773286819458 loss: 22.1735\n",
      "0 w:-2.6472814083099365,b:3.7505617141723633 loss: 23.7868\n",
      "0 w:-2.6816089153289795,b:3.853544235229492 loss: 25.3482\n",
      "0 w:-2.7107343673706055,b:3.9465577602386475 loss: 20.6892\n",
      "0 w:-2.7407586574554443,b:4.0490546226501465 loss: 25.1356\n",
      "0 w:-2.7680280208587646,b:4.149042129516602 loss: 23.9311\n",
      "0 w:-2.789836883544922,b:4.235405445098877 loss: 17.8615\n",
      "0 w:-2.809583902359009,b:4.320403099060059 loss: 17.3081\n",
      "0 w:-2.8289239406585693,b:4.411578178405762 loss: 19.9225\n",
      "0 w:-2.8481204509735107,b:4.511602401733398 loss: 23.9855\n",
      "0 w:-2.8640284538269043,b:4.604243278503418 loss: 20.5813\n",
      "0 w:-2.8775453567504883,b:4.693454742431641 loss: 19.0908\n",
      "0 w:-2.8911449909210205,b:4.79702091217041 loss: 25.7348\n",
      "0 w:-2.901709794998169,b:4.892104625701904 loss: 21.6964\n",
      "0 w:-2.908794403076172,b:4.970034599304199 loss: 14.5765\n",
      "0 w:-2.915564775466919,b:5.0657854080200195 loss: 22.0084\n",
      "0 w:-2.920471429824829,b:5.162936687469482 loss: 22.6592\n",
      "0 w:-2.9233577251434326,b:5.258184909820557 loss: 21.7816\n",
      "0 w:-2.9243357181549072,b:5.354994773864746 loss: 22.5024\n",
      "0 w:-2.923391819000244,b:5.448445796966553 loss: 20.968\n",
      "0 w:-2.920806646347046,b:5.533759117126465 loss: 17.4748\n",
      "0 w:-2.916167736053467,b:5.625607967376709 loss: 20.2532\n",
      "0 w:-2.9099314212799072,b:5.713807106018066 loss: 18.6737\n",
      "0 w:-2.901886463165283,b:5.80230188369751 loss: 18.7967\n",
      "0 w:-2.8922741413116455,b:5.88881254196167 loss: 17.9603\n",
      "0 w:-2.8793978691101074,b:5.986871242523193 loss: 23.0705\n",
      "0 w:-2.864898681640625,b:6.082565784454346 loss: 21.9665\n",
      "0 w:-2.84908390045166,b:6.174664497375488 loss: 20.3411\n",
      "0 w:-2.831651210784912,b:6.265498161315918 loss: 19.7803\n",
      "0 w:-2.811492681503296,b:6.360531330108643 loss: 21.6444\n",
      "0 w:-2.787733316421509,b:6.462800025939941 loss: 25.0564\n",
      "0 w:-2.7671029567718506,b:6.544496536254883 loss: 15.9834\n",
      "0 w:-2.7404847145080566,b:6.642096519470215 loss: 22.8019\n",
      "0 w:-2.7137317657470703,b:6.733425617218018 loss: 19.9566\n",
      "0 w:-2.6879255771636963,b:6.8158392906188965 loss: 16.2424\n",
      "0 w:-2.6605608463287354,b:6.897933483123779 loss: 16.1082\n",
      "0 w:-2.6291067600250244,b:6.986904144287109 loss: 18.9088\n",
      "0 w:-2.593111276626587,b:7.083216190338135 loss: 22.1449\n",
      "0 w:-2.5548527240753174,b:7.180334091186523 loss: 22.5028\n",
      "0 w:-2.5184402465820312,b:7.268257141113281 loss: 18.4312\n",
      "0 w:-2.474745988845825,b:7.3688554763793945 loss: 24.1114\n",
      "0 w:-2.4280669689178467,b:7.4715495109558105 loss: 25.108\n",
      "0 w:-2.3828580379486084,b:7.566776752471924 loss: 21.5731\n",
      "0 w:-2.3392295837402344,b:7.654923915863037 loss: 18.4695\n",
      "0 w:-2.2882142066955566,b:7.75395393371582 loss: 23.2921\n",
      "0 w:-2.2369163036346436,b:7.8497748374938965 loss: 21.7879\n",
      "0 w:-2.1836905479431152,b:7.945580959320068 loss: 21.7616\n",
      "0 w:-2.1347906589508057,b:8.030512809753418 loss: 17.0858\n",
      "0 w:-2.0930943489074707,b:8.100478172302246 loss: 11.5834\n",
      "0 w:-2.029998540878296,b:8.202879905700684 loss: 24.7884\n",
      "0 w:-1.9812521934509277,b:8.279481887817383 loss: 13.8567\n",
      "0 w:-1.9244898557662964,b:8.365935325622559 loss: 17.6311\n",
      "0 w:-1.8557887077331543,b:8.467449188232422 loss: 24.2819\n",
      "0 w:-1.7954449653625488,b:8.55402946472168 loss: 17.6431\n",
      "0 w:-1.7311691045761108,b:8.643653869628906 loss: 18.8833\n",
      "0 w:-1.6779038906097412,b:8.715889930725098 loss: 12.2522\n",
      "0 w:-1.6251194477081299,b:8.785565376281738 loss: 11.3846\n",
      "0 w:-1.56510329246521,b:8.8627290725708 loss: 13.9453\n",
      "0 w:-1.4958051443099976,b:8.949570655822754 loss: 17.6397\n",
      "0 w:-1.4336826801300049,b:9.025498390197754 loss: 13.4661\n",
      "0 w:-1.3734697103500366,b:9.097318649291992 loss: 12.032\n",
      "0 w:-1.3071109056472778,b:9.174607276916504 loss: 13.9141\n",
      "0 w:-1.2352492809295654,b:9.256381034851074 loss: 15.5532\n",
      "0 w:-1.1781589984893799,b:9.319886207580566 loss: 9.36615\n",
      "0 w:-1.1192944049835205,b:9.383925437927246 loss: 9.50998\n",
      "0 w:-1.0575562715530396,b:9.449646949768066 loss: 10.0004\n",
      "0 w:-0.9837517738342285,b:9.526558876037598 loss: 13.6742\n",
      "0 w:-0.9156674742698669,b:9.596047401428223 loss: 11.1436\n",
      "0 w:-0.8352028727531433,b:9.676511764526367 loss: 14.9174\n",
      "1 w:-0.7842393517494202,b:9.625548362731934 loss: 5.98413\n",
      "1 w:-0.7273802757263184,b:9.567517280578613 loss: 7.772\n",
      "1 w:-0.6861809492111206,b:9.524582862854004 loss: 4.26105\n",
      "1 w:-0.6453533172607422,b:9.481121063232422 loss: 4.3734\n",
      "1 w:-0.5996201038360596,b:9.431366920471191 loss: 5.74031\n",
      "1 w:-0.5600920915603638,b:9.387397766113281 loss: 4.49001\n",
      "1 w:-0.5348271727561951,b:9.358648300170898 loss: 1.92248\n",
      "1 w:-0.5135431289672852,b:9.333858489990234 loss: 1.43142\n",
      "1 w:-0.48864811658859253,b:9.30416488647461 loss: 2.05675\n",
      "1 w:-0.468901127576828,b:9.280029296875 loss: 1.36065\n",
      "1 w:-0.4501279592514038,b:9.256503105163574 loss: 1.29456\n",
      "1 w:-0.4337420165538788,b:9.235435485839844 loss: 1.03952\n",
      "1 w:-0.42382073402404785,b:9.222339630126953 loss: 0.4022\n",
      "1 w:-0.4015975892543793,b:9.192201614379883 loss: 2.13273\n",
      "1 w:-0.39168158173561096,b:9.178375244140625 loss: 0.449422\n",
      "1 w:-0.378141313791275,b:9.158947944641113 loss: 0.888312\n",
      "1 w:-0.36673909425735474,b:9.14210033416748 loss: 0.66886\n",
      "1 w:-0.35628968477249146,b:9.126185417175293 loss: 0.597508\n",
      "1 w:-0.3467513620853424,b:9.111196517944336 loss: 0.530541\n",
      "1 w:-0.3348986506462097,b:9.091959953308105 loss: 0.874747\n",
      "1 w:-0.3298572599887848,b:9.083500862121582 loss: 0.169332\n",
      "1 w:-0.3313136696815491,b:9.086030006408691 loss: 0.0151558\n",
      "1 w:-0.3268722593784332,b:9.078035354614258 loss: 0.151528\n",
      "1 w:-0.3234011232852936,b:9.071551322937012 loss: 0.0997608\n",
      "1 w:-0.3182983994483948,b:9.061646461486816 loss: 0.233028\n",
      "1 w:-0.31584489345550537,b:9.056689262390137 loss: 0.0584102\n",
      "1 w:-0.31582310795783997,b:9.05664348602295 loss: 5.01841e-06\n",
      "1 w:-0.3137188255786896,b:9.052014350891113 loss: 0.0510238\n",
      "1 w:-0.311923086643219,b:9.047880172729492 loss: 0.0407249\n",
      "1 w:-0.31298109889030457,b:9.050435066223145 loss: 0.0155602\n",
      "1 w:-0.31089675426483154,b:9.045144081115723 loss: 0.0667908\n",
      "1 w:-0.3122011721134186,b:9.04863452911377 loss: 0.0290816\n",
      "1 w:-0.31506216526031494,b:9.056727409362793 loss: 0.156438\n",
      "1 w:-0.31919795274734497,b:9.069134712219238 loss: 0.367941\n",
      "1 w:-0.3202928304672241,b:9.072630882263184 loss: 0.0292363\n",
      "1 w:-0.32438793778419495,b:9.086610794067383 loss: 0.467603\n",
      "1 w:-0.3277742266654968,b:9.099027633666992 loss: 0.369032\n",
      "1 w:-0.32769542932510376,b:9.098715782165527 loss: 0.000233093\n",
      "1 w:-0.3275029957294464,b:9.097887992858887 loss: 0.00164355\n",
      "1 w:-0.32880863547325134,b:9.104043006896973 loss: 0.0907995\n",
      "1 w:-0.33183544874191284,b:9.119813919067383 loss: 0.59631\n",
      "1 w:-0.33340123295783997,b:9.128931999206543 loss: 0.199388\n",
      "1 w:-0.33436882495880127,b:9.1353178024292 loss: 0.0978268\n",
      "1 w:-0.337179958820343,b:9.156725883483887 loss: 1.09959\n",
      "1 w:-0.3386872112751007,b:9.17029094696045 loss: 0.441605\n",
      "1 w:-0.33841684460639954,b:9.167317390441895 loss: 0.0212278\n",
      "1 w:-0.3395085632801056,b:9.182757377624512 loss: 0.572271\n",
      "1 w:-0.34038805961608887,b:9.20017147064209 loss: 0.72802\n",
      "1 w:-0.34087494015693665,b:9.216238975524902 loss: 0.619804\n",
      "1 w:-0.34105849266052246,b:9.23440933227539 loss: 0.792722\n",
      "1 w:-0.34090355038642883,b:9.249750137329102 loss: 0.565045\n",
      "1 w:-0.34066954255104065,b:9.257472038269043 loss: 0.143176\n",
      "1 w:-0.3399236798286438,b:9.27224063873291 loss: 0.523604\n",
      "1 w:-0.3391018509864807,b:9.28386402130127 loss: 0.324301\n",
      "1 w:-0.3379727900028229,b:9.296283721923828 loss: 0.370217\n",
      "1 w:-0.33675795793533325,b:9.307217597961426 loss: 0.286877\n",
      "1 w:-0.3337405025959015,b:9.330196380615234 loss: 1.26692\n",
      "1 w:-0.3305414021015167,b:9.351310729980469 loss: 1.06938\n",
      "1 w:-0.3274470865726471,b:9.369330406188965 loss: 0.778696\n",
      "1 w:-0.32413429021835327,b:9.386591911315918 loss: 0.714316\n",
      "1 w:-0.3194732367992401,b:9.408565521240234 loss: 1.15716\n",
      "1 w:-0.3125665783882141,b:9.438294410705566 loss: 2.11732\n",
      "1 w:-0.3101206421852112,b:9.447979927062988 loss: 0.224669\n",
      "1 w:-0.3029946982860565,b:9.474108695983887 loss: 1.63418\n",
      "1 w:-0.2970164716243744,b:9.49451732635498 loss: 0.996524\n",
      "1 w:-0.29324111342430115,b:9.506573677062988 loss: 0.347627\n",
      "1 w:-0.28913605213165283,b:9.518888473510742 loss: 0.362494\n",
      "1 w:-0.2821418344974518,b:9.53867244720459 loss: 0.934947\n",
      "1 w:-0.2717767059803009,b:9.56640625 loss: 1.83624\n",
      "1 w:-0.26028749346733093,b:9.595571517944336 loss: 2.02936\n",
      "1 w:-0.2517508566379547,b:9.61618423461914 loss: 1.01303\n",
      "1 w:-0.23700518906116486,b:9.65013313293457 loss: 2.74602\n",
      "1 w:-0.22031180560588837,b:9.686858177185059 loss: 3.21112\n",
      "1 w:-0.20608897507190704,b:9.716816902160645 loss: 2.13518\n",
      "1 w:-0.19440892338752747,b:9.740415573120117 loss: 1.32375\n",
      "1 w:-0.17626430094242096,b:9.77563762664795 loss: 2.94646\n",
      "1 w:-0.15871848165988922,b:9.808411598205566 loss: 2.54896\n",
      "1 w:-0.14008380472660065,b:9.841954231262207 loss: 2.66743\n",
      "1 w:-0.12656983733177185,b:9.865426063537598 loss: 1.30492\n",
      "1 w:-0.12100928276777267,b:9.874756813049316 loss: 0.206004\n",
      "1 w:-0.09475255757570267,b:9.917369842529297 loss: 4.29268\n",
      "1 w:-0.08350082486867905,b:9.935050964355469 loss: 0.738265\n",
      "1 w:-0.0648399069905281,b:9.963473320007324 loss: 1.90558\n",
      "1 w:-0.03479698300361633,b:10.007864952087402 loss: 4.64344\n",
      "1 w:-0.013617221266031265,b:10.038253784179688 loss: 2.17346\n",
      "1 w:0.011040670797228813,b:10.072635650634766 loss: 2.77903\n",
      "1 w:0.02428654208779335,b:10.090599060058594 loss: 0.757682\n",
      "1 w:0.036703553050756454,b:10.106989860534668 loss: 0.630001\n",
      "1 w:0.056058187037706375,b:10.131874084472656 loss: 1.45031\n",
      "1 w:0.08445508778095245,b:10.167460441589355 loss: 2.96202\n",
      "1 w:0.10549122095108032,b:10.193171501159668 loss: 1.5441\n",
      "1 w:0.1244877278804779,b:10.215829849243164 loss: 1.19758\n",
      "1 w:0.1495548039674759,b:10.245025634765625 loss: 1.98548\n",
      "1 w:0.1801043152809143,b:10.279788970947266 loss: 2.81083\n",
      "1 w:0.19591662287712097,b:10.297377586364746 loss: 0.718502\n",
      "1 w:0.21359162032604218,b:10.316606521606445 loss: 0.857414\n",
      "1 w:0.2342822253704071,b:10.338631629943848 loss: 1.1232\n",
      "1 w:0.26723426580429077,b:10.372971534729004 loss: 2.72585\n",
      "1 w:0.2947132885456085,b:10.401017189025879 loss: 1.81525\n",
      "1 w:0.3348709046840668,b:10.441174507141113 loss: 3.71551\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "train_X=np.linspace(-1,1,100)\n",
    "train_Y=2*train_X+np.random.randn(*train_X.shape)*0.33+10\n",
    "X=tf.placeholder(\"float\")\n",
    "Y=tf.placeholder(\"float\")\n",
    "w=tf.Variable(0.0,name=\"weight\")\n",
    "b=tf.Variable(0.0,name=\"bias\")\n",
    "loss=(tf.square(Y-tf.mul(X,w)-b))\n",
    "train_op=tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(2):\n",
    "        for (x,y) in zip(train_X,train_Y): #将矩阵拆解为多个数值，所以循环一步是对100个train_X的值进行训练\n",
    "            _,w_value,b_value=sess.run([train_op,w,b],feed_dict={X:x,Y:y})  \n",
    "            print(step,\"w:{},b:{}\".format(w_value,b_value),\"loss:\",sess.run(loss,feed_dict={X:x,Y:y}))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:0,w:0.01359501201659441,b:0.1993873119354248 loss: 156.016\n",
      "step:200,w:1.4918266534805298,b:9.797532081604004 loss: 2.00011\n",
      "step:400,w:1.8693699836730957,b:9.966344833374023 loss: 0.753242\n",
      "step:600,w:1.9657955169677734,b:9.96930980682373 loss: 0.5906\n",
      "step:800,w:1.9904229640960693,b:9.969343185424805 loss: 0.553304\n",
      "step:1000,w:1.996712565422058,b:9.969343185424805 loss: 0.543987\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "train_X=np.linspace(-1,1,100)\n",
    "train_Y=2*train_X+np.random.randn(*train_X.shape)*0.33+10\n",
    "X=tf.placeholder(\"float\")\n",
    "Y=tf.placeholder(\"float\")\n",
    "w=tf.Variable(0.0,name=\"weight\")\n",
    "b=tf.Variable(0.0,name=\"bias\")\n",
    "loss=tf.reduce_mean(tf.square(Y-tf.mul(X,w)-b))\n",
    "train_op=tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(1001):\n",
    "                         #与上例子相比，去除zip之后，每一次循环是对整个数据集train_X进行训练,并且对loss需要求平均值\n",
    "            _,w_value,b_value=sess.run([train_op,w,b],feed_dict={X:train_X,Y:train_Y})\n",
    "            if step%200 ==0:\n",
    "                print(\"step:{},w:{},b:{}\".format(step,w_value,b_value),\"loss:\",sess.run(loss,feed_dict={X:x,Y:y}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.35376003  0.0292071   0.66601101 -1.34881032 -0.14200387 -0.46975305\n",
      "  0.36523579  0.54440909 -0.23484962 -0.08653737  0.9806797  -0.54640561\n",
      "  1.05888572 -0.00322656 -0.47402539 -1.03716933  0.66507602  0.86491453\n",
      " -2.42748033 -0.80069824 -0.25501756 -2.05386022  0.23420528  1.20909299\n",
      " -0.96849704  0.68283906  0.19665299 -1.145284   -0.9188656  -0.148315\n",
      "  0.39342494 -2.12867469  0.24144593 -1.47398674  0.33962214  1.13025683\n",
      "  0.46997667 -0.01001835 -0.60398584  1.01838594  0.1906777   0.87745621\n",
      "  1.78380099  0.79445611  0.88667811  0.91053494  0.54698326 -0.85735114\n",
      " -1.57932275  1.09402707 -0.82363554  0.79044756  0.63224988  0.26089443\n",
      " -0.23245883  0.24022123  1.44216457 -0.40372239  1.38048955  1.23725202\n",
      "  0.06220507 -0.13769528  0.54702277 -0.32234302  0.31507592 -0.42870861\n",
      " -0.04016403  1.47426841  0.3877371   0.48188228  0.26300286 -0.77120501\n",
      " -1.01158813  1.46328437 -1.30376898 -1.73112283 -0.92224421  0.51330125\n",
      "  0.23388815 -0.03819296  1.73636234 -1.87181215 -1.32812115 -2.37247026\n",
      "  3.07657968 -1.49340312  0.28845979 -0.44056698  0.53971427  0.31277842\n",
      " -0.44656772 -0.61138648 -0.38049831 -0.43700231 -2.1465173  -1.80613192\n",
      " -0.87699824 -0.36757388 -0.51754995 -0.53921146]\n",
      "[-0.26566646  0.98999732  0.71318339 -1.34342901  1.33521133  1.00682347\n",
      " -0.74934976  0.96267632 -0.50569045  0.32138361 -2.10880235  1.20497813\n",
      "  0.16123948  1.70588421  0.17452226 -0.71147958 -1.80447657  0.32789913\n",
      " -0.44168748 -1.29626067 -0.57949375 -0.26365875 -1.38373365  0.46149701\n",
      "  0.53189113  0.13396597  0.17552913 -1.86028763 -0.49954205  0.56363193\n",
      "  1.16703724  0.97326021  0.7146022   1.0742691  -0.15564427 -0.3741164\n",
      " -0.34295777 -0.38123648 -0.00903537  0.98774376  0.34162137  1.41775983\n",
      "  1.53471629 -0.96797724  1.16858814 -0.73737258  0.43622483  0.17415617\n",
      " -0.18567602 -2.44658266  1.31500527  0.94553641 -0.14462338  0.11271977\n",
      "  0.18649894 -1.37913177 -0.11953255 -0.04193347  0.21325416  0.63142731\n",
      " -0.00741868 -0.39051616  1.11765828  0.51764351 -1.02768262 -0.16402895\n",
      " -0.93298452 -0.28969575  0.3915361  -1.25140798  0.72459381  0.22027729\n",
      " -0.58443288 -0.62954693  0.79481499 -0.06119061  2.15677127 -1.3781399\n",
      " -1.17793115 -1.41114921 -1.4169276   0.5542796   0.85257728 -0.37871686\n",
      "  0.0514743   1.94557082  0.64783109  1.78809764  0.47875895 -0.78012681\n",
      "  0.17483829  0.12685929  1.81072222  1.84730953  0.41539419 -0.09894406\n",
      "  2.07199098 -0.46979029  0.94120171 -0.36932429]\n"
     ]
    }
   ],
   "source": [
    "train_X=np.linspace(-1,1,100)\n",
    "train_X.shape\n",
    "print(np.random.randn(*train_X.shape)) #标准正态分布 -2.58~2.58\n",
    "print(np.random.randn(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
